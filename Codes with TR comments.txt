###Veri çekme,excel dosyasına yazdırma için gerekli kütüphaneleri tanımladım.###
from bs4 import BeautifulSoup
import requests
import xlsxwriter 

###Veri çekeceğim url'yi ve çekeceğim sayfayı daha rahat tanımlayabilmek için string dizisi tanımladım.###
user_agent = {'User-agent': 'Mozilla/5.0'}
url = "https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?view=detailed&page="
sayfaIndex = ["0","1","2","3","4","5"]

###Tanımladığım kütüphaneyi kullanarak excel dosyası ve içine iki sayfa oluşturarak değişkenlere atadım.###
workbook = xlsxwriter.Workbook('veriSeti.xlsx') 
islenmemis = workbook.add_worksheet("İşlenmemiş Veri") 
islenmis = workbook.add_worksheet("Ön işlemeden geçmiş veri")
satir = 0
sutun = 0

###Toplamda 6 sayfadan veri çekeceğim için her sayfayı ayrı ele alabilmek açısından bir for döngüsü açtım.###
###Her döngüde bir sonraki sayfayı tanımladığım diziden sayfa indexini alarak çektim.###
for index in sayfaIndex:

    ###Sayfaya gerekli isteği yolladım ve sayfa verilerini source değişkenine atadım.###
    r = requests.get(url+index, headers = user_agent)
    source = BeautifulSoup(r.content,"lxml")
    ###Gereksiz kısımlarla uğraşmamak için sayfanın yalnızca işime yarayacak kısmını oyunlar değişkenine atadım.###
    ###Böylece her bir oyunun verisini içeren bölümler dizi şeklinde oyunlar değişkenine tanımlanmış oldu.###
    oyunlar = source.find_all("td",attrs={"class":"clamp-summary-wrap"})
    
    ###Mevcut döngünün altına yeni bir for açarak her oyunu tek tek ele almayı amaçladım.###
    for oyun in oyunlar:
        ###İstediğim verileri içeren bölümleri tanımladığım kütüphanelerle çekerek farklı değişkenlere attım.###
        oyunAdi = oyun.find("a",attrs={"class":"title"}).text.lstrip().rstrip()
        platform = oyun.find("span",attrs={"class":"data"}).text.lstrip().rstrip()
        metaScore = oyun.find("div", attrs={"class":"clamp-metascore"}).findChildren()[1].text.lstrip().rstrip()
        userScore = oyun.find("div", attrs={"class":"clamp-userscore"}).findChildren()[1].text.lstrip().rstrip()
        if userScore == "tbd":
            continue
        cikisTarihi = oyun.find("div", attrs={"class":"clamp-details"}).findChildren()[3].text.split(", ")[1].lstrip().rstrip()
        metaScore=float(metaScore)
        oyunUrl = oyun.find("a",attrs={"class":"title"},href=True)
        oyunUrl = "https://www.metacritic.com"+oyunUrl["href"]
        r2 = requests.get(oyunUrl, headers = user_agent)
        source2 = BeautifulSoup(r2.content,"lxml")
        developerCompany = source2.find("span",attrs={"class":"data"}).text.split(",")[0].lstrip().rstrip()
        genres = source2.find("li",attrs={"class":"product_genre"}).findChildren()

	###Verilerin bulunduğu değişkenleri tek bir dizide topladım.###
        icerik = [oyunAdi,platform,metaScore,userScore,cikisTarihi,developerCompany,genres[2].text]
        
	###Her sütuna oyun verilerini sırasıyla yazdırmak için yeni bir for döngüsü açtım.### 
        for detay in icerik:
	    ###Gerekli verileri excel dosyasının işlenmemiş veriler için olan sayfasına sütunlar halinde yazdırdım.###
            islenmemis.write(satir, sutun, detay)
            sutun += 1
    	###Bir sonraki oyunda alt satıra geçilmesi için satır değişkenine bir ekledim.###
        sutun = 0
        satir += 1
###İşlenmemiş verilerin çekilmesi ve excel dosyasına yazılmasını bitirdim.###
print("TARAMA TAMAMLANDI!")

###Ön işleme için ihtiyacım olan kütüphaneleri tanımladım.###
import numpy as np
import pandas as pd

###İşlenmemiş verilerin olduğu sayfadan tüm verileri çektim ve kütüphanelerin desteklediği csv formatına dönüştürdüm.###
data_xlsx = pd.read_excel('veriSeti.xlsx', 'İşlenmemiş Veri', index_col=False)
data_xlsx.to_csv('csvfile.csv', encoding='utf-8', index=True)
### csv uzantılı dosyadaki tüm verileri okuyup dataset değişkenine atadım.###
dataset = pd.read_csv('csvfile.csv')

###İhtiyacım olmayan sütünları ayıklayıp ihtiyacım olanları X değişkenine atadım.###
X = dataset.iloc[:,[True,False,True,True,True,True,True,True]].values

###Ön işleme adımları için gerekli kütüphaneleri tanımladım.###
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder 
from sklearn.compose import ColumnTransformer 

###Sayısal verileri scale edebilmek için StandartScaler kullandım ve gerekli verileri scale ettim.###
sc = StandardScaler()
metascoreIsleme = sc.fit_transform(X[:, 2:3]) #scaled
userscoreIsleme = sc.fit_transform(X[:, 3:4]) #scaled

oyunAddi = dataset.iloc[:, 1].values
###Encode edilecek verileri dataset içinden alarak farklı değişkenlere atadım.###
platformIsleme = dataset.iloc[:, 2].values  #encoded
yearIsleme = dataset.iloc[:, 5].values      #encoded
developerIsleme = dataset.iloc[:, 6].values #encoded
categoryIsleme = dataset.iloc[:, 7].values  #encoded

###Encode edilmesi gereken string verileri tek tek endcode ettim ve değişkenlere atadım.###
columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough') 
platformIsleme = pd.get_dummies(platformIsleme)
platformIsleme = np.array(platformIsleme)
platformIsleme = np.array(columnTransformer.fit_transform(platformIsleme), dtype = np.str) 

yearIsleme = pd.get_dummies(yearIsleme)
yearIsleme = np.array(yearIsleme)
yearIsleme = np.array(columnTransformer.fit_transform(yearIsleme), dtype = np.str) 

developerIsleme = pd.get_dummies(developerIsleme)
developerIsleme = np.array(developerIsleme)
developerIsleme = np.array(columnTransformer.fit_transform(developerIsleme), dtype = np.str) 

categoryIsleme = pd.get_dummies(categoryIsleme)
categoryIsleme = np.array(categoryIsleme)
categoryIsleme = np.array(columnTransformer.fit_transform(categoryIsleme), dtype = np.str)

satir=1
sutun=0
###İşlenen verileri daha kolay yazabilmek için hepsini dizi içine aldım ve bir for oluşturdum.###
islenenler = [oyunAddi,platformIsleme,metascoreIsleme,userscoreIsleme,yearIsleme,developerIsleme,categoryIsleme]
for islenen in islenenler:
    for detay in islenen:
	###İşlenen verileri işlenmemiş olanlardan farklı bir excel sayfasına yazdırdım.###
        islenmis.write(satir,sutun,str(detay))
        satir = satir+1

    satir=1
    sutun = sutun+1

workbook.close()
###Excel dosyasını kapattım ve işlenenleri yazmayı bitirdim.###
print("YAZMA TAMAMLANDI !!")
